{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Practica2-2.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"jxw0BZv75hCz","colab_type":"text"},"source":["###Apartado 3: Transferencia de modelos y ajuste fino con ResNet50 para la base de datos Caltech-UCSD."]},{"cell_type":"code","metadata":{"id":"L96TiVml4iVm","colab_type":"code","colab":{}},"source":["# Alumno : Daniel Bolaños Martínez 76592621E\n","# Asignatura : Visión por Computador\n","# Práctica 2 : Introducción a Keras para la clasificación de imágenes\n","\n","# -*- coding: utf-8 -*-\n","\n","#########################################################################\n","################### OBTENER LA BASE DE DATOS ############################\n","#########################################################################\n","\n","# Descargar las imágenes de http://www.vision.caltech.edu/visipedia/CUB-200.html\n","# Descomprimir el fichero.\n","# Descargar también el fichero list.tar.gz, descomprimirlo y guardar los ficheros\n","# test.txt y train.txt dentro de la carpeta de imágenes anterior. Estos \n","# dos ficheros contienen la partición en train y test del conjunto de datos.\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","! unzip /content/drive/My\\ Drive/VC/images.zip -d /content/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LuQwGvkz4qlo","colab_type":"code","colab":{}},"source":["#########################################################################\n","################ CARGAR LAS LIBRERÍAS NECESARIAS ########################\n","#########################################################################\n","\n","# Terminar de rellenar este bloque con lo que vaya haciendo falta\n","\n","# Importar librerías necesarias\n","import numpy as np\n","import keras\n","import keras.utils as np_utils\n","from keras.preprocessing.image import load_img, img_to_array\n","import matplotlib.pyplot as plt\n","\n","# Importar el optimizador a usar\n","from keras.optimizers import SGD\n","\n","# Importar DataGenerator\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","# Importar modelos y capas específicas que se van a usar\n","\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n","from keras import backend as K\n","# Import Early Stopping\n","from keras.callbacks import EarlyStopping\n","\n","# Importar el modelo ResNet50 y su respectiva función de preprocesamiento,\n","# que es necesario pasarle a las imágenes para usar este modelo\n","\n","from keras.applications.resnet import ResNet50, preprocess_input\n","\n","# Importar el optimizador a usar\n","from keras.optimizers import SGD"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hxYFTkg743VS","colab_type":"code","colab":{}},"source":["\n","#########################################################################\n","################## FUNCIÓN PARA LEER LAS IMÁGENES #######################\n","#########################################################################\n","\n","# Dado un fichero train.txt o test.txt y el path donde se encuentran los\n","# ficheros y las imágenes, esta función lee las imágenes\n","# especificadas en ese fichero y devuelve las imágenes en un vector y \n","# sus clases en otro.\n","\n","def leerImagenes(vec_imagenes, path):\n","  clases = np.array([img.split('/')[0] for img in vec_imagenes])\n","  imagenes = np.array([img_to_array(load_img(path + \"/\" + img, \n","                                             target_size = (224, 224))) \n","                       for img in vec_imagenes])\n","  return imagenes, clases\n","\n","#########################################################################\n","############# FUNCIÓN PARA CARGAR EL CONJUNTO DE DATOS ##################\n","#########################################################################\n","\n","# Usando la función anterior, y dado el path donde se encuentran las\n","# imágenes y los archivos \"train.txt\" y \"test.txt\", devuelve las \n","# imágenes y las clases de train y test para usarlas con keras\n","# directamente.\n","\n","def cargarDatos(path):\n","  # Cargamos los ficheros\n","  train_images = np.loadtxt(path + \"/train.txt\", dtype = str)\n","  test_images = np.loadtxt(path + \"/test.txt\", dtype = str)\n","  \n","  # Leemos las imágenes con la función anterior\n","  train, train_clases = leerImagenes(train_images, path)\n","  test, test_clases = leerImagenes(test_images, path)\n","  \n","  # Pasamos los vectores de las clases a matrices \n","  # Para ello, primero pasamos las clases a números enteros\n","  clases_posibles = np.unique(np.copy(train_clases))\n","  for i in range(len(clases_posibles)):\n","    train_clases[train_clases == clases_posibles[i]] = i\n","    test_clases[test_clases == clases_posibles[i]] = i\n","\n","  # Después, usamos la función to_categorical()\n","  train_clases = np_utils.to_categorical(train_clases, 200)\n","  test_clases = np_utils.to_categorical(test_clases, 200)\n","  \n","  # Barajar los datos\n","  train_perm = np.random.permutation(len(train))\n","  train = train[train_perm]\n","  train_clases = train_clases[train_perm]\n","\n","  test_perm = np.random.permutation(len(test))\n","  test = test[test_perm]\n","  test_clases = test_clases[test_perm]\n","  \n","  return train, train_clases, test, test_clases\n","\n","#########################################################################\n","######## FUNCIÓN PARA OBTENER EL ACCURACY DEL CONJUNTO DE TEST ##########\n","#########################################################################\n","\n","# Esta función devuelve el accuracy de un modelo, definido como el \n","# porcentaje de etiquetas bien predichas frente al total de etiquetas.\n","# Como parámetros es necesario pasarle el vector de etiquetas verdaderas\n","# y el vector de etiquetas predichas, en el formato de keras (matrices\n","# donde cada etiqueta ocupa una fila, con un 1 en la posición de la clase\n","# a la que pertenece y 0 en las demás).\n","\n","def calcularAccuracy(labels, preds):\n","  labels = np.argmax(labels, axis = 1)\n","  preds = np.argmax(preds, axis = 1)\n","  \n","  accuracy = sum(labels == preds)/len(labels)\n","  \n","  return accuracy\n","\n","#########################################################################\n","## FUNCIÓN PARA PINTAR LA PÉRDIDA Y EL ACCURACY EN TRAIN Y VALIDACIÓN ###\n","#########################################################################\n","\n","# Esta función pinta dos gráficas, una con la evolución de la función\n","# de pérdida en el conjunto de train y en el de validación, y otra\n","# con la evolución del accuracy en el conjunto de train y en el de\n","# validación. Es necesario pasarle como parámetro el historial\n","# del entrenamiento del modelo (lo que devuelven las funciones\n","# fit() y fit_generator()).\n","\n","def mostrarEvolucion(hist):\n","\n","  loss = hist.history['loss']\n","  val_loss = hist.history['val_loss']\n","  plt.plot(loss)\n","  plt.plot(val_loss)\n","  plt.legend(['Training loss', 'Validation loss'])\n","  plt.show()\n","\n","  acc = hist.history['acc']\n","  val_acc = hist.history['val_acc']\n","  plt.plot(acc)\n","  plt.plot(val_acc)\n","  plt.legend(['Training accuracy', 'Validation accuracy'])\n","  plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x1ADXAn897VI","colab_type":"code","colab":{}},"source":["# input image dimensions\n","num_classes = 200\n","batch_size = 32\n","epochs = 20\n","\n","# cargamos los datos\n","x_train, y_train, x_test, y_test = cargarDatos('/content/images')\n","\n","## Usar ResNet50 preentrenada en ImageNet como un extractor de características\n","\n","# Definir un objeto de la clase ImageDataGenerator para train y otro para test\n","# con sus respectivos argumentos.\n","\n","datagen_train = ImageDataGenerator(preprocessing_function=preprocess_input)\n","datagen_test = ImageDataGenerator(preprocessing_function=preprocess_input)\n","\n","train = datagen_train.flow(x_train, y_train, batch_size = 1, shuffle = False)\n","test = datagen_test.flow(x_test, batch_size = 1, shuffle = False)\n","\n","# Definir el modelo ResNet50 (preentrenado en ImageNet y sin la última capa).\n","\n","resnet50 = ResNet50(include_top=False, weights='imagenet', pooling='avg')\n","resnet50.summary()\n","\n","# Extraer las características las imágenes con el modelo anterior.\n","\n","train_features = resnet50.predict_generator(train)\n","test_features = resnet50.predict_generator(test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a9NiCRJX47s6","colab_type":"code","colab":{}},"source":["# Las características extraídas en el paso anterior van a ser la entrada\n","# de un pequeño modelo de dos capas Fully Conected, donde la última será la que \n","# nos clasifique las clases de Caltech-UCSD (200 clases). De esta forma, es \n","# como si hubiéramos fijado todos los parámetros de ResNet50 y estuviésemos\n","# entrenando únicamente las capas añadidas. Definir dicho modelo.\n","\n","input_shape = (2048,)\n","\n","model = Sequential()\n","model.add(Dense(512, activation='relu', input_shape=input_shape))\n","model.add(Dropout(0.5))\n","model.add(Dense(256, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes, activation='softmax'))\n","model.summary()\n","\n","# explicar por qué selecciono ese optimizador\n","\n","opt = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","\n","model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=opt,\n","              metrics=['acc'])\n","\n","# Una vez tenemos el modelo base, y antes de entrenar, vamos a guardar los\n","# pesos aleatorios con los que empieza la red, para poder reestablecerlos\n","# después y comparar resultados entre no usar mejoras y sí usarlas.\n","\n","weights = model.get_weights()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7kWB-jftbDx-","colab_type":"code","colab":{}},"source":["model.set_weights(weights)\n","\n","epochs = 40\n","\n","# En la función fit() puedes usar el argumento validation_split\n","\n","histograma = model.fit(train_features, y_train, epochs=epochs, validation_split=0.1,\n","                       callbacks = [EarlyStopping(monitor = 'val_acc', patience = 4, restore_best_weights = True)])\n","mostrarEvolucion(histograma)\n","\n","preds = model.predict(test_features)\n","score = calcularAccuracy(y_test, preds)\n","print(\"Predicción sobre conjunto Test\")\n","print(\"Test accuracy = \" + str(score))\n","# Predicción sobre el conjunto de Train\n","preds = model.predict(train_features)\n","score = calcularAccuracy(y_train, preds)\n","print(\"Predicción sobre conjunto Train\")\n","print(\"Train accuracy = \" + str(score))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9MYhQBKvOeU5","colab_type":"code","colab":{}},"source":["## Reentrenar ResNet50 (fine tunning)\n","\n","# Definir un objeto de la clase ImageDataGenerator para train y otro para test\n","# con sus respectivos argumentos.\n","\n","datagen_train_norm = ImageDataGenerator(preprocessing_function=preprocess_input, featurewise_center = True, \n","                                        featurewise_std_normalization = True, horizontal_flip=True, zoom_range=0.0, validation_split=0.1)\n","datagen_test_norm = ImageDataGenerator(preprocessing_function=preprocess_input, featurewise_center = True, \n","                                       featurewise_std_normalization = True)\n","\n","# Añadir nuevas capas al final de ResNet50 (recuerda que es una instancia de\n","# la clase Model).\n","\n","epochs=20\n","\n","x = resnet50.output\n","x = Dense(512, activation='relu')(x)\n","x = Dropout(0.75)(x)\n","x = Dense(256, activation='relu')(x)\n","x = Dropout(0.5)(x)\n","last = Dense(num_classes, activation='softmax')(x)\n","new_model = Model(inputs = resnet50.input, outputs = last)\n","\n","opt = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","\n","new_model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=opt,\n","              metrics=['acc'])\n","\n","# Una vez tenemos el modelo base, y antes de entrenar, vamos a guardar los\n","# pesos aleatorios con los que empieza la red, para poder reestablecerlos\n","# después y comparar resultados entre no usar mejoras y sí usarlas.\n","\n","weights = new_model.get_weights()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ypUzXlopYeit","colab_type":"code","colab":{}},"source":["new_model.set_weights(weights)\n","\n","datagen_train_norm.fit(x_train)\n","datagen_test_norm.fit(x_train)\n","train_norm = datagen_train_norm.flow(x_train, y_train, batch_size = batch_size, subset = 'training')\n","validation_norm = datagen_train_norm.flow(x_train, y_train, batch_size = batch_size, subset = 'validation')\n","\n","histograma = new_model.fit_generator(train_norm, steps_per_epoch = len(x_train)*0.9/batch_size, epochs = epochs, \n","                    validation_data = validation_norm, validation_steps = len(x_train)*0.1/batch_size)\n","\n","mostrarEvolucion(histograma)\n","preds = new_model.predict_generator(datagen_test_norm.flow(x_test, batch_size = 1, shuffle = False), steps=len(x_test))\n","score = calcularAccuracy(y_test, preds)\n","print(\"Predicción sobre conjunto Test\")\n","print(\"Test accuracy = \" + str(score))\n","# Predicción sobre el conjunto de Train\n","preds = new_model.predict_generator(datagen_train_norm.flow(x_train, batch_size = 1, shuffle = False), steps = len(x_train))\n","score = calcularAccuracy(y_train, preds)\n","print(\"Predicción sobre conjunto Train\")\n","print(\"Train accuracy = \" + str(score))"],"execution_count":0,"outputs":[]}]}